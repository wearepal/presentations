<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/simple.css" id="theme">
    <link rel="stylesheet" href="custom.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="footer">
        <p>Topics in Computer Science</p>
      </div>
<div class="slides">

<section data-markdown data-background-image="University_of_Sussex_Logo.svg.png" data-background-size="15%" data-background-position="50% 85%">
<textarea data-template>
# Algorithmic fairness

by Oliver Thomas and Thomas Kehrenberg
</textarea></section>

<section data-markdown><textarea data-template>
## Machine Learning

> ...using statistical techniques to give computer systems the ability to "learn"
  (e.g., progressively improve performance on a specific task)
  from data, without being explicitly programmed.
</textarea></section>

<section data-markdown><textarea data-template>
## Classification

- given some input $x$, predict a class label $y \in \\{0, 1, ..., C-1\\}$
- $x$ is usually a **vector**
  - often with high number of dimensions, e.g. more than 1 million for a picture
- simplest case: **binary classification**, $y \in \\{0, 1\\}$
  - for example: is there a hot dog in this picture ($y=1$) or not ($y=0$)?
</textarea></section>

<section data-markdown><textarea data-template>
## Classification

- we are looking to train a function $f$ that maps $x$ to $y$
- the output is the prediction: $\hat{y} = f(x)$
- we want $\hat{y}$ to be as close as possible to the label $y$
- $f$ can be implemented as
  - a neural network
  - an SVM
  - a logistic regression model
</textarea></section>

<section data-markdown><textarea data-template>
## Training data

- training data: a set of pairs $(x, y)$
  - input data $x$ with corresponding label $y$
- we are looking for model that works well on the training data
- if we make predictions on data that is *very different* from the training data,
  the model will perform badly
- problem if the training data does not describe reality well
</textarea></section>

<section data-markdown><textarea data-template>
## Where is machine learning used?

- hiring decisions
- bail decisions
- credit approval
- insurance premiums

<aside class="notes">
  Companies are already using or planning to use machine learning for these tasks.
</aside>
</textarea></section>

<section>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
But there are problems:
</section>

<section>
    <img class="stretch" src="pp_mb.png" title="Pro-Publica - Machine Bias"/>
</section>

<section>
    <img class="stretch" src="amazon.png" title="Amazon CV Screening"/>
</section>

<section data-markdown><textarea data-template>
## Algorithmic bias

- machine learning systems are making decisions that affect humans
- these decisions should be *fair*
- by default machine learning algorithms tend to be biased in some way
  - why?
</textarea></section>

<section data-markdown><textarea data-template>
## Algorithmic bias

The problem can be divided into <ins>two categories</ins>. Both types of bias can appear together.

- bias stemming from biased training data
- bias stemming from the algorithms themselves
</textarea></section>

<section>
  <section data-markdown><textarea data-template>
  # Biased training data
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  ## Bias in, bias out
  
  - Databases: GIGO
  - ML: BIBO
    - the ML algorithm just learns what is in the training data
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  ## Examples for bias
  
  **Task**: generate description for images
  
  ![](./images/women_also_snowboard/title.png)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  ![](./images/women_also_snowboard/example1.png)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  ## Learning wrong features
  
  The algorithm predicts the gender from the activity and not from looking at the person.
  
  ![](./images/women_also_snowboard/example2.png)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  (how was it solved in this case?)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  (in the previous example the problem was that the data was incomplete,
  but it could also be that the data is just wrong)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  (if the data is biased in some kind we can nevertheless try to enforce a fair outcome)

  (how do we define a fair outcome?)
  </textarea></section>
  
  <section data-markdown><textarea data-template>
  ## Statistical parity
  
  $$
  P(\hat{Y}=1 | S=0) = P(\hat{Y}=1 | S=1)
  $$
  $$
  Y \in \{0,1\} \\
  S \in \{0,1\}
  $$ 
  </textarea></section>

  <section data-markdown><textarea data-template>
  (what does the definition mean...?)

  (discuss trade-off with accuracy)

  (later somewhere: causal fairness definitions)
  </textarea></section>

  <section data-markdown><textarea data-template>
  
  </textarea></section>
</section>

<section>
  <section data-markdown><textarea data-template>
  # Bias introduced by the ML algorithm
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Why would an ML algorithm introduce bias?

  Consider the following dataset:

  - two features: SAT score and gender of individuals

  - task: predict if they earn more than <span>$</span>50K per year ($y=1$) or not ($y=0$)

  - composition of the dataset: 50% female, 50% male. 20% of female have $y=1$, 50% of male have $y=1$.
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Bias from algorithm

  The dataset is heavily skewed but let's ignore that for now and just try to make accurate predictions for this dataset.
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Bias from algorithm

  Reminder: 20% of female have $y=1$, 50% of male have $y=1$.

  A simple way to make relatively accurate predictions:
  - for male individuals base the prediction on SAT
  - for female individuals ignore SAT score and always predict $y=0$

  Result: up to 90% accuracy
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Bias from algorithm

  - the dataset was already skewed but the algorithm's prediction are even more "unfair"
  - this is because it's easier to just base the decision on gender than to figure out the effect of the SAT
  - this is an extreme case but similar things actually can happen
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Bias from algorithm
  
  **What we don't want:** the algorithm missclassifying a subgroup

  **What we want:** the algorithm should make equally good predictions for all subgroups

  Criterion that enforces this: *Equality of Opportunity*
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Equality of Opportunity

  $$
  P(\hat{Y}=1 | S=0, Y=1) = P(\hat{Y}=1 | S=1, Y=1)
  $$
  $$
  Y \in \{0,1\} \\
  S \in \{0,1\}
  $$ 
  </textarea></section>

  <section data-markdown><textarea data-template>
  (dicsuss equality of opportunity)

  (also mention Equalised Odds)
  </textarea></section>

  <section data-markdown><textarea data-template>
  ## Equalised Odds

  $$
  P(\hat{Y}=1 | S=0, Y=y) = P(\hat{Y}=1 | S=1, Y=y)
  $$
  $$
  Y \in \{0,1\} \\
  S \in \{0,1\}
  $$ 
  </textarea></section>

  <section data-markdown><textarea data-template>
  
  </textarea></section>

  <section data-markdown><textarea data-template>
  
  </textarea></section>

  <section data-markdown><textarea data-template>
  
  </textarea></section>

  <section data-markdown><textarea data-template>
  
  </textarea></section>
</section>

<section data-markdown><textarea data-template>
# Enforcing fairness criteria
</textarea></section>

<section data-markdown><textarea data-template>

</textarea></section>

<section data-markdown><textarea data-template>
</textarea></section>

<section data-markdown><textarea data-template>
</textarea></section>

<section data-markdown><textarea data-template>
</textarea></section>

<section data-markdown><textarea data-template>

</textarea></section>

<section data-markdown><textarea data-template>

</textarea></section>

<section data-markdown><textarea data-template>
## How to enforce fairness?

Fairness constraints can be added pre, during or post training.

Pre-training examples
- Zemel Fair Representations
- Beutel Adversarial Representation
- Quadrianto Fair Interpretable Representations
- Feldman
</textarea></section>

<section data-markdown><textarea data-template>
During Training
- Zafar's methods
- Zhang
- Kehrenberg Fair GP

Post Training
- Hardt Recalibrating
</textarea></section>

<section data-markdown><textarea data-template>

</textarea></section>

</div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
      // More info about config & dependencies:
      // - https://github.com/hakimel/reveal.js#configuration
      // - https://github.com/hakimel/reveal.js#dependencies
      Reveal.initialize({
        markdown: {
          smartypants: true,
          gfm: true
        },
        math: {
          config: 'TeX-AMS_HTML-full'
        },
        dependencies: [
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/math/math.js', async: true }
        ],
        // Display presentation control arrows
        controls: true,
        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,
        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',
        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',
        // Display a presentation progress bar
        progress: false,
        // Display the page number of the current slide
        slideNumber: 'c/t',
        // Push each slide change to the browser history
        history: true,
        // Enable keyboard shortcuts for navigation
        keyboard: true,
        // Enable the slide overview mode
        overview: true,
        // Vertical centering of slides
        center: false,
        // Enables touch navigation on devices with touch input
        touch: true,
        // Loop the presentation
        loop: false,
        // Change the presentation direction to be RTL
        rtl: false,
        // Randomizes the order of slides each time the presentation loads
        shuffle: false,
        // Turns fragments on and off globally
        fragments: true,
        // whether to include the current fragment in the URL, so that reloading brings you to the same fragment position
        fragmentInURL: true,
        // whether the presentation is running in an embedded mode, i.e. contained within a limited portion of the screen
        embedded: false,
        // whether we should show a help overlay when the questionmark key is pressed
        help: true,
        // whether speaker notes should be visible to all viewers
        showNotes: false,
        // Global override for autoplaying embedded media (video/audio/iframe)
        // - null: Media will only autoplay if data-autoplay is present
        // - true: All media will autoplay, regardless of individual setting
        // - false: No media will autoplay, regardless of individual setting
        autoPlayMedia: null,
        // Number of milliseconds between automatically proceeding to the next slide,
        // disabled when set to 0, this value can be overwritten by using a data-autoslide attribute on your slides
        autoSlide: 0,
        // Stop auto-sliding after user input
        autoSlideStoppable: true,
        // Use this method for navigation when auto-sliding
        autoSlideMethod: Reveal.navigateNext,
        // Specify the average time in seconds that you think you will spend presenting each slide.
        // This is used to show a pacing timer in the speaker view
        defaultTiming: 120,
        // Enable slide navigation via mouse wheel
        mouseWheel: false,
        // Hides the address bar on mobile devices
        hideAddressBar: true,
        // Opens links in an iframe preview overlay
        // Add `data-preview-link` and `data-preview-link="false"` to customise each link individually
        previewLinks: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition speed
        transitionSpeed: 'default', // default/fast/slow
        // Transition style for full page slide backgrounds
        backgroundTransition: 'none', // none/fade/slide/convex/concave/zoom
        // Number of slides away from the current that are visible
        viewDistance: 3,
        // Parallax background image
        // parallaxBackgroundImage: 'University_of_Sussex_Logo.svg.png', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"
        parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"
        // Parallax background size
        parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"
        // Number of pixels to move the parallax background per slide
        // - Calculated automatically unless specified
        // - Set to 0 to disable movement along an axis
        parallaxBackgroundHorizontal: null,
        parallaxBackgroundVertical: null,
        parallaxBackgroundRepeat: 'no-repeat',
        parallaxBackgroundPosition: '',
        // The display mode that will be used to show slides
        display: 'block'
      });
    </script>
  </body>
</html>
